import requests
import pandas as pd
from io import BytesIO
import os


# https://www.dataestur.es/en/apidata/


# Añadimos las urls de las que necesitamos descargar archivos. Key = Name; Value = URL

downloads = {
    "FRONTUR_DL": "https://dataestur.azure-api.net/API-SEGITTUR-v1/FRONTUR_DL?desde%20%28a%C3%B1o%29=2018&Pa%C3%ADs%20de%20residencia=Todos&Tipo%20de%20visitante=Todos&CCAA%20de%20destino=Todos",
    "EGATUR_DL": "https://dataestur.azure-api.net/API-SEGITTUR-v1/EGATUR_DL?desde%20%28a%C3%B1o%29=2018&Pa%C3%ADs%20de%20residencia=Todos&CCAA%20de%20destino=Todos"
}


# Creamos una función para descargar un diccionario de URLS. Para ello tenemos que pasarle la url y un nombre de archivo.
# La descarga devuelve un tipo binario, así que usamos BytesIO y lo convertimos en Dataframe con Pandas.

def download_excel(url, file_name, folder="./data"):
    file_path = os.path.join(folder, f"{file_name}.xlsx")

    if os.path.exists(file_path):
        print(f"⏭️  {file_name}.xlsx already exists.")
        return pd.read_excel(file_path)

    response = requests.get(url)
    
    if response.status_code == 200:
        df = pd.read_excel(BytesIO(response.content))
        df.to_excel(file_path, index=False)
        print(f"{file_name}.xlsx downloaded and saved.")
        return df
    else:
        print(f"Failed to download {file_name}: {response.status_code}")
        return None


# Guardamos todos los dataframes. Llamamos nuestra función para crear un nuevo diccionario de dataframes.

datasets = {}

for name, url in downloads.items():
    df = download_excel(url, name)
    if df is not None:
        datasets[name] = df


#Para visualizar datos en conjunto:

for name, df in datasets.items():
    print(f"\n {name}")
    print("Columns:", df.columns.tolist())
    print("First 3 rows:\n", df.head(3))


# Para visualizar un archivo en concreto:

datasets["FRONTUR_DL"].tail()


datasets["EGATUR_DL"].head()



